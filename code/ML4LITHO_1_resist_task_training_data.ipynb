{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c27d92c",
   "metadata": {},
   "source": [
    "# Microlithography Interactive Explorer â€“ Final Version\n",
    "\n",
    "All improvements included:\n",
    "- Exact vector polygons (no extraction)\n",
    "- Precomputed aerials\n",
    "- Mask inversion\n",
    "- Mack + simple resist tuning\n",
    "- nm scales + scalebars\n",
    "- origin='lower' (no upside-down patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0914cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torch torchvision matplotlib scipy numpy ipywidgets\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from scipy.ndimage import gaussian_filter, distance_transform_edt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import math\n",
    "\n",
    "# Device\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else\n",
    "                      'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "RAW_TRAINING_DATA_PATH = \"data/litho_dataset_training.npz\"\n",
    "ALL_PATCHES_DATA_PATH = \"data/litho_dataset_all_patches.npz\"\n",
    "SAMPLED_PATCHES_DATA_PATH = \"data/litho_dataset_sampled_patches.npz\"\n",
    "\n",
    "grid_size = 256\n",
    "pixel_size_nm = 5.0\n",
    "pad_ratio = 0.3\n",
    "full_width_nm = grid_size * pixel_size_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fffcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PBC helpers\n",
    "def pad_mask_for_pbc(mask, pad_ratio=0.3):\n",
    "    H, W = mask.shape\n",
    "    pad_h = int(H * pad_ratio)\n",
    "    pad_w = int(W * pad_ratio)\n",
    "    padded_size = H + 2 * pad_h\n",
    "    padded = torch.zeros((padded_size, padded_size), device=mask.device)\n",
    "    padded[pad_h:pad_h+H, pad_w:pad_w+W] = mask\n",
    "    return padded, pad_h, pad_w, padded_size\n",
    "\n",
    "def unpad(tensor, pad_h, pad_w):\n",
    "    H, W = tensor.shape\n",
    "    return tensor[pad_h:H-pad_h, pad_w:W-pad_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa16dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core simulation\n",
    "def create_pupil_and_freq(grid_size, na=1.35, wavelength_nm=193.0, pixel_size_nm=5.0):\n",
    "    lambda_m = wavelength_nm * 1e-9\n",
    "    f_cutoff = na / lambda_m\n",
    "    dx = pixel_size_nm * 1e-9\n",
    "    freq = torch.fft.fftfreq(grid_size, d=1.0, device=device)\n",
    "    FX, FY = torch.meshgrid(freq, freq, indexing='ij')\n",
    "    R = torch.sqrt(FX**2 + FY**2)\n",
    "    r_norm = f_cutoff * dx\n",
    "    pupil = (R <= r_norm).cfloat()\n",
    "    return pupil, FX, FY\n",
    "\n",
    "def create_source_points():\n",
    "    x = torch.linspace(-1, 1, 40, device=device)\n",
    "    y = torch.linspace(-1, 1, 40, device=device)\n",
    "    X, Y = torch.meshgrid(x, y, indexing='ij')\n",
    "    R = torch.sqrt(X**2 + Y**2).flatten()\n",
    "    theta = torch.atan2(Y.flatten(), X.flatten())\n",
    "    points_grid = torch.stack([X.flatten(), Y.flatten()], dim=1)\n",
    "    r_mask = (R >= 0.3) & (R <= 0.8)\n",
    "    half_angle = math.radians(30)/2\n",
    "    centers = [0, math.pi]\n",
    "    dists = torch.stack([torch.abs((theta - c + math.pi) % (2*math.pi) - math.pi) for c in centers])\n",
    "    mask = (dists.min(0).values <= half_angle) & r_mask\n",
    "    return points_grid[mask]\n",
    "\n",
    "def precompute_socs_kernels(source_points, pupil, FX, FY, num_kernels=80):\n",
    "    N = pupil.numel()\n",
    "    S = len(source_points)\n",
    "    A = torch.zeros((N, S), dtype=torch.cfloat, device=device)\n",
    "    for i, (sx, sy) in enumerate(source_points):\n",
    "        phase = torch.exp(2j * math.pi * (sx * FX + sy * FY))\n",
    "        A[:, i] = (pupil * phase).flatten() / math.sqrt(S)\n",
    "    U, S_eig, _ = torch.svd_lowrank(A.cpu(), q=num_kernels + 20)\n",
    "    kernels_freq = U[:, :num_kernels].to(device).reshape(pupil.shape[0], pupil.shape[1], num_kernels)\n",
    "    eigenvalues = (S_eig[:num_kernels] ** 2).to(device)\n",
    "    return kernels_freq, eigenvalues\n",
    "\n",
    "def simulate_aerial_socs(mask, kernels_freq, eigenvalues):\n",
    "    if mask.dim() == 2: mask = mask.unsqueeze(0)\n",
    "    mask_fft = torch.fft.fft2(mask)\n",
    "    aerial = torch.zeros_like(mask_fft, dtype=torch.float)\n",
    "    for k in range(eigenvalues.shape[0]):\n",
    "        field = torch.fft.ifft2(mask_fft * kernels_freq[:,:,k])\n",
    "        aerial += eigenvalues[k] * (field.abs() ** 2)\n",
    "    aerial = aerial.real\n",
    "    uniform_fft = torch.fft.fft2(torch.ones_like(mask))\n",
    "    clear = torch.zeros_like(aerial)\n",
    "    for k in range(eigenvalues.shape[0]):\n",
    "        field = torch.fft.ifft2(uniform_fft * kernels_freq[:,:,k])\n",
    "        clear += eigenvalues[k] * (field.abs() ** 2)\n",
    "    aerial /= (clear.real.mean() + 1e-10)\n",
    "    return aerial.squeeze(0).clamp_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd7807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resist models\n",
    "def mack_levelset_resist(aerial, dose=1.1, dill_C=0.07, r_max=70.0, n_mack=4.0, num_steps=150):\n",
    "    binary = (aerial > 0.3).cpu().numpy().astype(np.float32)\n",
    "    dist = (distance_transform_edt(binary) - distance_transform_edt(1-binary)).astype(np.float32)\n",
    "    phi = torch.from_numpy(dist).to(device)\n",
    "    phi.clamp_(-20, 20)\n",
    "    E = dose * aerial\n",
    "    M = torch.exp(-dill_C * E)\n",
    "    R = r_max * (1 - M)**n_mack + 0.1\n",
    "    dt = 0.35\n",
    "    for _ in range(num_steps):\n",
    "        xp = torch.roll(phi, -1, 1)\n",
    "        xm = torch.roll(phi,  1, 1)\n",
    "        yp = torch.roll(phi, -1, 0)\n",
    "        ym = torch.roll(phi,  1, 0)\n",
    "        g_plus  = torch.sqrt(torch.max(xp-phi, torch.zeros_like(phi))**2 + torch.max(yp-phi, torch.zeros_like(phi))**2)\n",
    "        g_minus = torch.sqrt(torch.max(phi-xm, torch.zeros_like(phi))**2 + torch.max(phi-ym, torch.zeros_like(phi))**2)\n",
    "        grad = torch.where(phi >= 0, g_plus, g_minus) + 1e-8\n",
    "        phi.sub_(dt * R * grad)\n",
    "    return torch.clamp((phi + 20) / 40 * 2.0, 0.0, 2.0)\n",
    "\n",
    "def simple_resist(aerial_np, thresh=0.25, steep=20.0, diff=2.8, load_sigma=16.0, gain=1.8):\n",
    "    diffused = gaussian_filter(aerial_np, sigma=diff)\n",
    "    loading = gaussian_filter(aerial_np, sigma=load_sigma)\n",
    "    effective = diffused + 0.20 * loading\n",
    "    res = 1.0 / (1.0 + np.exp(-steep * (effective - thresh)))\n",
    "    return np.clip(res * gain, 0.0, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2679e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure generators â€“ return (mask, polygons)\n",
    "def generate_L(size=256, cd=12, long=140, short=80):\n",
    "    m = torch.zeros((size,size), device=device)\n",
    "    cx, cy = size//2, size//2\n",
    "    # Vertical\n",
    "    vy1, vy2 = cy - long//2, cy + long//2\n",
    "    vx1, vx2 = cx - cd//2, cx + cd//2\n",
    "    m[vy1:vy2, vx1:vx2] = 1\n",
    "    # Horizontal\n",
    "    hy1, hy2 = cy + long//2 - cd//2, cy + long//2 + cd//2\n",
    "    hx1, hx2 = cx - cd//2, cx + short\n",
    "    m[hy1:hy2, hx1:hx2] = 1\n",
    "    return m, [[vx1,vy1,vx2,vy2], [hx1,hy1,hx2,hy2]]\n",
    "\n",
    "def generate_T(size=256, cd=12, stem=140, cross=100):\n",
    "    m = torch.zeros((size,size), device=device)\n",
    "    cx, cy = size//2, size//2\n",
    "    vy1, vy2 = cy - stem//2, cy + stem//2\n",
    "    vx1, vx2 = cx - cd//2, cx + cd//2\n",
    "    m[vy1:vy2, vx1:vx2] = 1\n",
    "    hy1, hy2 = cy - stem//2 - cd//2, cy - stem//2 + cd//2\n",
    "    hx1, hx2 = cx - cross//2, cx + cross//2\n",
    "    m[hy1:hy2, hx1:hx2] = 1\n",
    "    return m, [[vx1,vy1,vx2,vy2], [hx1,hy1,hx2,hy2]]\n",
    "\n",
    "def generate_line_srafs(size=256, cd=12, len=180, sw=4, ns=2, sp=30):\n",
    "    m = torch.zeros((size,size), device=device)\n",
    "    cx, cy = size//2, size//2\n",
    "    vy1, vy2 = cy - len//2, cy + len//2\n",
    "    vx1, vx2 = cx - cd//2, cx + cd//2\n",
    "    m[vy1:vy2, vx1:vx2] = 1\n",
    "    polys = [[vx1,vy1,vx2,vy2]]\n",
    "    for s in [-1,1]:\n",
    "        for k in range(1, ns+1):\n",
    "            x = cx + s * k * sp\n",
    "            if 0 <= x < size:\n",
    "                x1, x2 = x - sw//2, x + sw//2\n",
    "                m[:, x1:x2] = 1\n",
    "                polys.append([x1, 0, x2, size])\n",
    "    return m, polys\n",
    "\n",
    "def generate_L_srafs(size=256, cd=12, long=140, short=80, sw=4, ns=2, sp=30):\n",
    "    m, polys = generate_L(size, cd, long, short)\n",
    "    cx = size//2\n",
    "    for s in [-1,1]:\n",
    "        for k in range(1, ns+1):\n",
    "            x = cx + s * k * sp\n",
    "            if 0 <= x < size:\n",
    "                x1, x2 = x - sw//2, x + sw//2\n",
    "                m[:, x1:x2] = 1\n",
    "                polys.append([x1, 0, x2, size])\n",
    "    return m, polys\n",
    "\n",
    "def generate_vertical_lines(size=256, cd=12, pitch=24, num=8):\n",
    "    m = torch.zeros((size,size), device=device)\n",
    "    polys = []\n",
    "    cx = size//2\n",
    "    start = cx - (num * pitch)//2\n",
    "    for i in range(num):\n",
    "        x = start + i * pitch\n",
    "        if 0 <= x < size:\n",
    "            x1, x2 = x, x + cd\n",
    "            m[:, x1:x2] = 1\n",
    "            polys.append([x1, 0, x2, size])\n",
    "    return m, polys\n",
    "\n",
    "def generate_contacts(size=256, diam=14, pitch=40, grid=5):\n",
    "    m = torch.zeros((size,size), device=device)\n",
    "    polys = []\n",
    "    cx, cy = size//2, size//2\n",
    "    start_x = cx - (grid * pitch)//2\n",
    "    start_y = cy - (grid * pitch)//2\n",
    "    for i in range(grid):\n",
    "        for j in range(grid):\n",
    "            x = start_x + i * pitch\n",
    "            y = start_y + j * pitch\n",
    "            x1, x2 = x - diam//2, x + diam//2\n",
    "            y1, y2 = y - diam//2, y + diam//2\n",
    "            m[y1:y2, x1:x2] = 1\n",
    "            polys.append([x1, y1, x2, y2])\n",
    "    return m, polys\n",
    "\n",
    "def generate_horizontal_grating(size=256, cd=12, pitch=28, num=10):\n",
    "    m = torch.zeros((size,size), device=device)\n",
    "    polys = []\n",
    "    cy = size//2\n",
    "    start = cy - (num * pitch)//2\n",
    "    for i in range(num):\n",
    "        y = start + i * pitch\n",
    "        if 0 <= y < size:\n",
    "            y1, y2 = y, y + cd\n",
    "            m[y1:y2, :] = 1\n",
    "            polys.append([0, y1, size, y2])\n",
    "    return m, polys\n",
    "\n",
    "structures = {\n",
    "    'L-shape'             : generate_L,\n",
    "    'L + SRAFs'           : generate_L_srafs,\n",
    "    'T-junction'          : generate_T,\n",
    "    'Line + SRAFs'        : generate_line_srafs,\n",
    "    'Vertical lines'      : generate_vertical_lines,\n",
    "    'Contacts 5Ã—5'        : generate_contacts,\n",
    "    'Horizontal grating'  : generate_horizontal_grating,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a750860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing aerials...\n",
      "  L-shape\n",
      "  L + SRAFs\n",
      "  T-junction\n",
      "  Line + SRAFs\n",
      "  Vertical lines\n",
      "  Contacts 5Ã—5\n",
      "  Horizontal grating\n",
      "Precomputation complete.\n"
     ]
    }
   ],
   "source": [
    "# Precompute aerials + store polygons\n",
    "padded_size = grid_size + 2 * int(grid_size * pad_ratio)\n",
    "pupil, FX, FY = create_pupil_and_freq(padded_size)\n",
    "source_pts = create_source_points()\n",
    "kernels, evals = precompute_socs_kernels(source_pts, pupil, FX, FY)\n",
    "\n",
    "precomputed = {}\n",
    "print(\"Precomputing aerials...\")\n",
    "for name, gen in structures.items():\n",
    "    mask, polygons = gen()\n",
    "    padded, ph, pw, _ = pad_mask_for_pbc(mask)\n",
    "    ap = simulate_aerial_socs(padded, kernels, evals)\n",
    "    aerial = unpad(ap, ph, pw)\n",
    "    precomputed[name] = {\n",
    "        'mask': mask,\n",
    "        'aerial': aerial,\n",
    "        'aerial_np': aerial.cpu().numpy(),\n",
    "        'polygons': polygons\n",
    "    }\n",
    "    print(f\"  {name}\")\n",
    "print(\"Precomputation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a37fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c377ad529444f688274c7173e1a590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Structure', options=('L-shape', 'L + SRAFs', 'T-junction',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  Interactive Widget\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "dd_structure = widgets.Dropdown(options=list(structures), description='Structure')\n",
    "cb_invert    = widgets.Checkbox(value=False, description='Invert mask')\n",
    "cb_poly      = widgets.Checkbox(value=True,  description='Show polygons')\n",
    "btn_update   = widgets.Button(description='Update', button_style='success')\n",
    "\n",
    "dose   = widgets.FloatSlider(value=1.1, min=0.5, max=2.0, step=0.05, description='Dose')\n",
    "dill_c = widgets.FloatSlider(value=0.07, min=0.01, max=0.20, step=0.005, description='Dill C')\n",
    "r_max  = widgets.FloatSlider(value=70.0, min=20, max=200, step=5, description='R_max')\n",
    "n_mack = widgets.FloatSlider(value=4.0, min=1, max=10, step=0.25, description='n_Mack')\n",
    "steps  = widgets.IntSlider(value=150, min=50, max=400, step=25, description='Steps')\n",
    "\n",
    "thresh   = widgets.FloatSlider(value=0.25, min=0.0, max=0.8, step=0.01, description='Thresh')\n",
    "steep    = widgets.FloatSlider(value=20.0, min=5.0, max=50.0, step=1.0, description='Steepness')\n",
    "diff     = widgets.FloatSlider(value=2.8, min=0.5, max=8.0, step=0.2, description='Diff Ïƒ')\n",
    "load_sig = widgets.FloatSlider(value=16.0, min=5.0, max=40.0, step=1.0, description='Load Ïƒ')\n",
    "gain     = widgets.FloatSlider(value=1.8, min=0.5, max=3.0, step=0.1, description='Gain')\n",
    "\n",
    "model = widgets.ToggleButtons(options=['Mack', 'Simple'], value='Mack')\n",
    "\n",
    "def update(_):\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        sel = dd_structure.value\n",
    "        inv = cb_invert.value\n",
    "        data = precomputed[sel]\n",
    "        mask = 1.0 - data['mask'] if inv else data['mask']\n",
    "        polys = data['polygons'] if cb_poly.value else []\n",
    "\n",
    "        padded, ph, pw, _ = pad_mask_for_pbc(mask)\n",
    "        ap = simulate_aerial_socs(padded, kernels, evals)\n",
    "        aerial = unpad(ap, ph, pw)\n",
    "        aerial_np = aerial.cpu().numpy()\n",
    "\n",
    "        if model.value == 'Mack':\n",
    "            resist = mack_levelset_resist(aerial, dose.value, dill_c.value,\n",
    "                                           r_max.value, n_mack.value, steps.value)\n",
    "            resist_np = resist.cpu().numpy()\n",
    "        else:\n",
    "            resist_np = simple_resist(aerial_np, thresh.value, steep.value,\n",
    "                                      diff.value, load_sig.value, gain.value)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(19, 6))\n",
    "        for ax in axes:\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set_xlabel('nm')\n",
    "\n",
    "        axes[0].imshow(mask.cpu().numpy(), cmap='gray', extent=[0,full_width_nm,full_width_nm,0], origin='lower')\n",
    "        axes[0].set_title(f\"Mask â€“ {sel}{' (inv)' if inv else ''}\")\n",
    "        # Inside update(), where you draw polygons on axes[0] (mask plot)\n",
    "        for p in polys:\n",
    "            xmin, ymin, xmax, ymax = [v * pixel_size_nm for v in p]\n",
    "            \n",
    "            # Mirror y-coordinates because origin='lower' flipped the axis direction\n",
    "            y1_flipped = full_width_nm - ymax   # original ymax becomes new bottom\n",
    "            y2_flipped = full_width_nm - ymin   # original ymin becomes new top\n",
    "            \n",
    "            # Now draw rectangle with corrected y-order (y1_flipped < y2_flipped)\n",
    "            rect = patches.Rectangle(\n",
    "                (xmin, y1_flipped),           # bottom-left corner\n",
    "                xmax - xmin,                  # width\n",
    "                y2_flipped - y1_flipped,      # height\n",
    "                edgecolor='cyan',\n",
    "                facecolor='none',\n",
    "                lw=1.8\n",
    "            )\n",
    "            axes[0].add_patch(rect)\n",
    "        axes[1].imshow(aerial_np, cmap='hot', extent=[0,full_width_nm,full_width_nm,0], origin='lower')\n",
    "        axes[1].set_title('Aerial')\n",
    "\n",
    "        im = axes[2].imshow(resist_np, cmap='viridis', vmin=0,vmax=2,\n",
    "                            extent=[0,full_width_nm,full_width_nm,0], origin='lower')\n",
    "        axes[2].contour(resist_np>0.5, colors='red', lw=3,\n",
    "                        extent=[0,full_width_nm,full_width_nm,0], origin='lower')\n",
    "        axes[2].set_title(f'Resist â€“ {model.value}')\n",
    "        fig.colorbar(im, ax=axes[2], shrink=0.6)\n",
    "\n",
    "        sb_nm = 200\n",
    "        sb_x = full_width_nm - sb_nm - 20\n",
    "        for ax in axes:\n",
    "            ax.plot([sb_x, sb_x+sb_nm], [20,20], 'w', lw=4)\n",
    "            ax.text(sb_x+sb_nm/2, 35, f'{sb_nm} nm', color='w', ha='center', va='bottom', fontsize=9,\n",
    "                    bbox=dict(fc='black', alpha=0.5, ec='none'))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "btn_update.on_click(update)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([dd_structure, cb_invert, cb_poly, btn_update]),\n",
    "    widgets.HBox([model]),\n",
    "    widgets.HBox([dose, dill_c, r_max, n_mack, steps]),\n",
    "    widgets.HBox([thresh, steep, diff, load_sig, gain]),\n",
    "    out\n",
    "]))\n",
    "\n",
    "update(None)  # initial plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "579ebaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities by name:\n",
      "  isolated_horizontal_line     : 0.10256\n",
      "  isolated_vertical_line       : 0.10256\n",
      "  horizontal_grating           : 0.10256\n",
      "  vertical_grating             : 0.10256\n",
      "  L_shape                      : 0.11538\n",
      "  T_shape                      : 0.10256\n",
      "  U_shape                      : 0.08974\n",
      "  line_with_srafs_vertical     : 0.10256\n",
      "  line_with_srafs_horizontal   : 0.08974\n",
      "  contacts_5x5                 : 0.08974\n",
      "Sum: 1.0\n",
      "Generating 200 samples...\n",
      "Generating 200 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de007d77ce6478abdee754ac18cd55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved â†’ 200 samples\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  TRAINING DATA GENERATION + INTERACTIVE BROWSER\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# â”€â”€â”€â”€ Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "NUM_SAMPLES       = 200          # change to 5000 or 10000 when ready\n",
    "HOTSPOT_FRACTION  = 0.10\n",
    "OUTPUT_PATH       = RAW_TRAINING_DATA_PATH\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Use the same optics as the interactive widget\n",
    "pixel_size_nm     = 5.0\n",
    "pad_ratio         = 0.3\n",
    "\n",
    "# â”€â”€â”€â”€ Helpers (copied/adapted from earlier draft) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def perturb_to_hotspot(mask):\n",
    "    mask = mask.clone()\n",
    "    size = grid_size\n",
    "    cx, cy = size // 2, size // 2\n",
    "    num_perturb = np.random.randint(3, 8)\n",
    "    for _ in range(num_perturb):\n",
    "        x = np.random.randint(cx - 80, cx + 80)\n",
    "        y = np.random.randint(cy - 80, cy + 80)\n",
    "        sz = np.random.randint(5, 20)\n",
    "        if np.random.rand() < 0.5:\n",
    "            mask[max(0, y-sz//2):min(size, y+sz//2),\n",
    "                 max(0, x-sz//2):min(size, x+sz//2)] = 1.0\n",
    "        else:\n",
    "            mask[max(0, y-sz//2):min(size, y+sz//2),\n",
    "                 max(0, x-sz//2):min(size, x+sz//2)] = 0.0\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#  REPLACEMENT: Full set of training structure generators\n",
    "#  Each returns (mask: torch.Tensor, polygons: list[list[float|int]])\n",
    "# =============================================================================\n",
    "\n",
    "def generate_isolated_horizontal_line(size=256, cd_px=12, length_px=180):\n",
    "    m = torch.zeros((size, size), device=device)\n",
    "    cy = size // 2\n",
    "    y1 = cy - cd_px // 2\n",
    "    y2 = cy + cd_px // 2\n",
    "    x1 = (size - length_px) // 2\n",
    "    x2 = x1 + length_px\n",
    "    m[y1:y2, x1:x2] = 1.0\n",
    "    return m, [[x1, y1, x2, y2]]\n",
    "\n",
    "\n",
    "def generate_isolated_vertical_line(size=256, cd_px=12, length_px=180):\n",
    "    m = torch.zeros((size, size), device=device)\n",
    "    cx = size // 2\n",
    "    x1 = cx - cd_px // 2\n",
    "    x2 = cx + cd_px // 2\n",
    "    y1 = (size - length_px) // 2\n",
    "    y2 = y1 + length_px\n",
    "    m[y1:y2, x1:x2] = 1.0\n",
    "    return m, [[x1, y1, x2, y2]]\n",
    "\n",
    "\n",
    "def generate_horizontal_grating(size=256, cd_px=12, pitch_px=28, num_lines=12):\n",
    "    m = torch.zeros((size, size), device=device)\n",
    "    polys = []\n",
    "    cy = size // 2\n",
    "    start_y = cy - (num_lines * pitch_px) // 2\n",
    "    for i in range(num_lines):\n",
    "        y = start_y + i * pitch_px\n",
    "        if 0 <= y < size - cd_px:\n",
    "            y1, y2 = y, y + cd_px\n",
    "            m[y1:y2, :] = 1.0\n",
    "            polys.append([0, y1, size, y2])\n",
    "    return m, polys\n",
    "\n",
    "\n",
    "def generate_vertical_grating(size=256, cd_px=12, pitch_px=28, num_lines=12):\n",
    "    m = torch.zeros((size, size), device=device)\n",
    "    polys = []\n",
    "    cx = size // 2\n",
    "    start_x = cx - (num_lines * pitch_px) // 2\n",
    "    for i in range(num_lines):\n",
    "        x = start_x + i * pitch_px\n",
    "        if 0 <= x < size - cd_px:\n",
    "            x1, x2 = x, x + cd_px\n",
    "            m[:, x1:x2] = 1.0\n",
    "            polys.append([x1, 0, x2, size])\n",
    "    return m, polys\n",
    "\n",
    "\n",
    "def generate_L(size=256, cd_px=12, long_px=140, short_px=80):\n",
    "    m = torch.zeros((size, size), device=device)\n",
    "    cx, cy = size // 2, size // 2\n",
    "    # vertical\n",
    "    vy1 = cy - long_px // 2\n",
    "    vy2 = cy + long_px // 2\n",
    "    vx1 = cx - cd_px // 2\n",
    "    vx2 = cx + cd_px // 2\n",
    "    m[vy1:vy2, vx1:vx2] = 1.0\n",
    "    # horizontal\n",
    "    hy1 = cy + long_px // 2 - cd_px // 2\n",
    "    hy2 = cy + long_px // 2 + cd_px // 2\n",
    "    hx1 = cx - cd_px // 2\n",
    "    hx2 = cx + short_px\n",
    "    m[hy1:hy2, hx1:hx2] = 1.0\n",
    "    return m, [[vx1, vy1, vx2, vy2], [hx1, hy1, hx2, hy2]]\n",
    "\n",
    "\n",
    "def generate_T(size=256, cd_px=12, stem_px=140, cross_px=100):\n",
    "    m = torch.zeros((size, size), device=device)\n",
    "    cx, cy = size // 2, size // 2\n",
    "    # vertical stem\n",
    "    vy1 = cy - stem_px // 2\n",
    "    vy2 = cy + stem_px // 2\n",
    "    vx1 = cx - cd_px // 2\n",
    "    vx2 = cx + cd_px // 2\n",
    "    m[vy1:vy2, vx1:vx2] = 1.0\n",
    "    # horizontal cross\n",
    "    hy1 = cy - stem_px // 2 - cd_px // 2\n",
    "    hy2 = cy - stem_px // 2 + cd_px // 2\n",
    "    hx1 = cx - cross_px // 2\n",
    "    hx2 = cx + cross_px // 2\n",
    "    m[hy1:hy2, hx1:hx2] = 1.0\n",
    "    return m, [[vx1, vy1, vx2, vy2], [hx1, hy1, hx2, hy2]]\n",
    "\n",
    "\n",
    "def generate_U(size=256, cd_px=12, height_px=140, width_px=100):\n",
    "    m = torch.zeros((size, size), device=device)\n",
    "    cx, cy = size // 2, size // 2\n",
    "    # left leg\n",
    "    lx1 = cx - width_px // 2\n",
    "    lx2 = lx1 + cd_px\n",
    "    ly1 = cy - height_px // 2\n",
    "    ly2 = cy + height_px // 2\n",
    "    m[ly1:ly2, lx1:lx2] = 1.0\n",
    "    # right leg\n",
    "    rx1 = cx + width_px // 2 - cd_px\n",
    "    rx2 = cx + width_px // 2\n",
    "    m[ly1:ly2, rx1:rx2] = 1.0\n",
    "    # bottom\n",
    "    by1 = cy + height_px // 2 - cd_px\n",
    "    by2 = cy + height_px // 2\n",
    "    bx1 = cx - width_px // 2\n",
    "    bx2 = cx + width_px // 2\n",
    "    m[by1:by2, bx1:bx2] = 1.0\n",
    "    return m, [[lx1,ly1,lx2,ly2], [rx1,ly1,rx2,ly2], [bx1,by1,bx2,by2]]\n",
    "\n",
    "\n",
    "def add_symmetric_srafs(mask, center_x, center_y, is_vertical=True,\n",
    "                        sraf_width=4, num_per_side=2, spacing=30):\n",
    "    \"\"\"Add symmetric SRAFs to a vertical or horizontal feature\"\"\"\n",
    "    m = mask.clone()\n",
    "    polys_add = []\n",
    "    size = mask.shape[0]\n",
    "    for side in [-1, 1]:\n",
    "        for k in range(1, num_per_side + 1):\n",
    "            offset = k * spacing\n",
    "            if is_vertical:\n",
    "                x = center_x + side * offset\n",
    "                if 0 <= x < size:\n",
    "                    x1 = x - sraf_width // 2\n",
    "                    x2 = x + sraf_width // 2\n",
    "                    m[:, x1:x2] = 1.0\n",
    "                    polys_add.append([x1, 0, x2, size])\n",
    "            else:\n",
    "                y = center_y + side * offset\n",
    "                if 0 <= y < size:\n",
    "                    y1 = y - sraf_width // 2\n",
    "                    y2 = y + sraf_width // 2\n",
    "                    m[y1:y2, :] = 1.0\n",
    "                    polys_add.append([0, y1, size, y2])\n",
    "    return m, polys_add\n",
    "\n",
    "\n",
    "def generate_line_with_srafs(size=256, cd_px=12, length_px=180, vertical=True):\n",
    "    if vertical:\n",
    "        m, polys = generate_isolated_vertical_line(size, cd_px, length_px)\n",
    "        cx = size // 2\n",
    "        m, sraf_polys = add_symmetric_srafs(m, cx, None, is_vertical=True)\n",
    "    else:\n",
    "        m, polys = generate_isolated_horizontal_line(size, cd_px, length_px)\n",
    "        cy = size // 2\n",
    "        m, sraf_polys = add_symmetric_srafs(m, None, cy, is_vertical=False)\n",
    "    polys.extend(sraf_polys)\n",
    "    return m, polys\n",
    "\n",
    "\n",
    "def generate_contacts(size=256, diam_px=14, pitch_px=40, grid=5):\n",
    "    m = torch.zeros((size, size), device=device)\n",
    "    polys = []\n",
    "    cx, cy = size // 2, size // 2\n",
    "    start_x = cx - (grid * pitch_px) // 2\n",
    "    start_y = cy - (grid * pitch_px) // 2\n",
    "    for i in range(grid):\n",
    "        for j in range(grid):\n",
    "            x = start_x + i * pitch_px\n",
    "            y = start_y + j * pitch_px\n",
    "            if 0 <= x < size and 0 <= y < size:\n",
    "                x1 = x - diam_px // 2\n",
    "                x2 = x + diam_px // 2\n",
    "                y1 = y - diam_px // 2\n",
    "                y2 = y + diam_px // 2\n",
    "                m[y1:y2, x1:x2] = 1.0\n",
    "                polys.append([x1, y1, x2, y2])\n",
    "    return m, polys\n",
    "\n",
    "\n",
    "# Dictionary for random selection during dataset generation\n",
    "training_generators = {\n",
    "    'isolated_horizontal_line': generate_isolated_horizontal_line,\n",
    "    'isolated_vertical_line':   generate_isolated_vertical_line,\n",
    "    'horizontal_grating':       generate_horizontal_grating,\n",
    "    'vertical_grating':         generate_vertical_grating,\n",
    "    'L_shape':                  generate_L,\n",
    "    'T_shape':                  generate_T,\n",
    "    'U_shape':                  generate_U,\n",
    "    'line_with_srafs_vertical': lambda: generate_line_with_srafs(vertical=True),\n",
    "    'line_with_srafs_horizontal': lambda: generate_line_with_srafs(vertical=False),\n",
    "    'contacts_5x5':             generate_contacts,\n",
    "}\n",
    "\n",
    "\n",
    "# Probabilities (you can adjust)\n",
    "# Weights for each generator (order must match training_generators.keys())\n",
    "generator_weights = {\n",
    "    'isolated_horizontal_line': 8,\n",
    "    'isolated_vertical_line':   8,\n",
    "    'horizontal_grating':       8,\n",
    "    'vertical_grating':         8,\n",
    "    'L_shape':                  9,\n",
    "    'T_shape':                  8,\n",
    "    'U_shape':                  7,\n",
    "    'line_with_srafs_vertical': 8,\n",
    "    'line_with_srafs_horizontal': 7,\n",
    "    'contacts_5x5':             7,\n",
    "    'contacts_with_srafs':      8,\n",
    "    'jogged_line':              7,\n",
    "    'hammerhead_line':          7,\n",
    "}\n",
    "\n",
    "# Build probs array in correct key order\n",
    "keys = list(training_generators.keys())\n",
    "weights_array = [generator_weights.get(k, 1.0) for k in keys]  # 1.0 fallback if missing\n",
    "training_probs = np.array(weights_array, dtype=np.float64)\n",
    "training_probs /= training_probs.sum()\n",
    "\n",
    "print(\"Probabilities by name:\")\n",
    "for k, p in zip(keys, training_probs):\n",
    "    print(f\"  {k:28s} : {p:.5f}\")\n",
    "print(\"Sum:\", training_probs.sum())\n",
    "# Or make some more frequent:\n",
    "# training_probs = [0.12, 0.12, 0.10, 0.10, 0.12, 0.10, 0.08, 0.10, 0.10, 0.06]\n",
    "# â”€â”€â”€â”€ Generate dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "dataset = {\n",
    "    'masks':    [],\n",
    "    'aerials':  [],\n",
    "    'resists':  [],\n",
    "    'polygons': [],\n",
    "    'params':   [],\n",
    "    'is_hotspot': []\n",
    "}\n",
    "\n",
    "print(f\"Generating {NUM_SAMPLES} samples...\")\n",
    "\n",
    "dataset = {\n",
    "    'masks':      [],\n",
    "    'aerials':    [],\n",
    "    'resists':    [],\n",
    "    'polygons':   [],\n",
    "    'params':     [],\n",
    "    'is_hotspot': []\n",
    "}\n",
    "\n",
    "print(f\"Generating {NUM_SAMPLES} samples...\")\n",
    "\n",
    "for i in tqdm(range(NUM_SAMPLES)):\n",
    "    typ = np.random.choice(list(training_generators.keys()), p=training_probs)\n",
    "    \n",
    "    # Get mask + polygons (no params dict returned yet)\n",
    "    mask, true_polygons = training_generators[typ]()\n",
    "    \n",
    "    # Create fresh params dict for this sample\n",
    "    params = {'type': typ}\n",
    "    \n",
    "    # Optional SRAFs on lines & L-variants (add to mask & polygons if needed)\n",
    "    if typ in ['near_limit_line', 'l_variant', 'isolated_horizontal_line', 'isolated_vertical_line']:\n",
    "        cx = grid_size // 2\n",
    "        for s in [-1, 1]:\n",
    "            for k in [1, 2]:\n",
    "                x = cx + s * k * 35\n",
    "                if 0 <= x < grid_size:\n",
    "                    mask[:, x-3:x+3] = 1.0\n",
    "                    # Optionally add SRAF polygons here too\n",
    "                    # true_polygons.append([x-3, 0, x+3, grid_size])\n",
    "\n",
    "    # Hotspot perturbation\n",
    "    is_hot = np.random.rand() < HOTSPOT_FRACTION\n",
    "    if is_hot:\n",
    "        mask = perturb_to_hotspot(mask)\n",
    "    \n",
    "    # Now store the params with hotspot flag\n",
    "    params['is_hotspot'] = is_hot\n",
    "\n",
    "    # Compute aerial & resist using current widget settings\n",
    "    padded, ph, pw, _ = pad_mask_for_pbc(mask)\n",
    "    aerial_p = simulate_aerial_socs(padded, kernels, evals)\n",
    "    aerial   = unpad(aerial_p, ph, pw)\n",
    "    aerial_np = aerial.cpu().numpy()\n",
    "\n",
    "    if model.value == 'Mack':\n",
    "        resist = mack_levelset_resist(aerial,\n",
    "                                      dose=dose.value,\n",
    "                                      dill_C=dill_c.value,\n",
    "                                      r_max=r_max.value,\n",
    "                                      n_mack=n_mack.value,\n",
    "                                      num_steps=steps.value)\n",
    "        resist_np = resist.cpu().numpy()\n",
    "    else:\n",
    "        resist_np = simple_resist(aerial_np,\n",
    "                                  thresh=thresh.value,\n",
    "                                  steep=steep.value,\n",
    "                                  diff=diff.value,\n",
    "                                  load_sigma=load_sig.value,\n",
    "                                  gain=gain.value)\n",
    "\n",
    "    # Append everything\n",
    "    dataset['masks'].append(mask.cpu().numpy())\n",
    "    dataset['aerials'].append(aerial_np)\n",
    "    dataset['resists'].append(resist_np)\n",
    "    dataset['polygons'].append(true_polygons)\n",
    "    dataset['params'].append(params)\n",
    "    dataset['is_hotspot'].append(is_hot)\n",
    "\n",
    "# â”€â”€â”€ Convert lists to numpy arrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "dataset['masks']    = np.array(dataset['masks'])\n",
    "dataset['aerials']  = np.array(dataset['aerials'])\n",
    "dataset['resists']  = np.array(dataset['resists'])\n",
    "dataset['polygons'] = np.array(dataset['polygons'], dtype=object)\n",
    "dataset['params']   = np.array(dataset['params'], dtype=object)\n",
    "dataset['is_hotspot'] = np.array(dataset['is_hotspot'])\n",
    "\n",
    "# Save\n",
    "np.savez_compressed(RAW_TRAINING_DATA_PATH, **dataset)\n",
    "print(f\"Dataset saved â†’ {len(dataset['masks'])} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506e947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 200 samples from data/litho_dataset_training.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf190e45411149d09db665f76cb3ce77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Sample:', max=199), Output()), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.view_sample(idx)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# â”€â”€â”€â”€ Interactive Dataset Browser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "data = np.load(RAW_TRAINING_DATA_PATH, allow_pickle=True)\n",
    "N = len(data['masks'])\n",
    "print(f\"Loaded dataset with {N} samples from {RAW_TRAINING_DATA_PATH}\")\n",
    "\n",
    "sample_slider = widgets.IntSlider(\n",
    "    value=0, min=0, max=N-1, step=1,\n",
    "    description='Sample:', continuous_update=False\n",
    ")\n",
    "\n",
    "def view_sample(idx):\n",
    "    mask    = data['masks'][idx]\n",
    "    aerial  = data['aerials'][idx]\n",
    "    resist  = data['resists'][idx]\n",
    "    polys   = data['polygons'][idx]\n",
    "    params  = data['params'][idx]\n",
    "    hotspot = data['is_hotspot'][idx]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(19, 6))\n",
    "    for ax in axes:\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_xlabel('nm')\n",
    "\n",
    "    # Mask + polygons\n",
    "    axes[0].imshow(mask, cmap='gray', extent=[0,full_width_nm,full_width_nm,0], origin='lower')\n",
    "    axes[0].set_title(f\"Mask â€“ {params['type']}\" + (\" ðŸ”¥\" if hotspot else \"\"))\n",
    "\n",
    "    if cb_poly.value and len(polys) > 0:\n",
    "        for poly in polys:\n",
    "            try:\n",
    "                # Expect [xmin, ymin, xmax, ymax]\n",
    "                if len(poly) == 4 and all(isinstance(v, (int, float)) for v in poly):\n",
    "                    x1, y1, x2, y2 = [v * pixel_size_nm for v in poly]\n",
    "                    axes[0].add_patch(patches.Rectangle(\n",
    "                        (x1, full_width_nm - y2),           # â† y-flip if needed\n",
    "                        x2 - x1,\n",
    "                        y2 - y1,\n",
    "                        ec='cyan', fc='none', lw=1.5\n",
    "                    ))\n",
    "                else:\n",
    "                    print(\"Skipping malformed polygon:\", poly)\n",
    "            except Exception as e:\n",
    "                print(\"Polygon drawing error:\", e, \"â†’ poly:\", poly)\n",
    "    # Aerial\n",
    "    axes[1].imshow(aerial, cmap='hot', extent=[0,full_width_nm,full_width_nm,0], origin='lower')\n",
    "    axes[1].set_title('Aerial')\n",
    "\n",
    "    # Resist + contour\n",
    "    im = axes[2].imshow(resist, cmap='viridis', vmin=0, vmax=2,\n",
    "                        extent=[0,full_width_nm,full_width_nm,0], origin='lower')\n",
    "    axes[2].contour(resist > 0.5, colors='red', lw=2.5,\n",
    "                    extent=[0,full_width_nm,full_width_nm,0], origin='lower')\n",
    "    axes[2].set_title('Resist + contour')\n",
    "\n",
    "    fig.colorbar(im, ax=axes[2], shrink=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "widgets.interact(view_sample, idx=sample_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04844094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Loading source dataset...\n",
      "â†’ 200 images\n",
      "Extracting ~10% random patches per image...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fbd02c85a6430fbea07c528f48c1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Images:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved fast candidates: data/litho_dataset_all_patches.npz\n",
      "Total extracted patches: 873,600\n",
      "Resist avg mean/min/max: 0.1006 / 0.0088 / 0.9998\n",
      "Area fraction mean/min/max: 0.0844 / 0.0000 / 1.0000\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  STAGE 1 â€“ FAST extraction: 10% random patches + batched torch interp\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# â”€â”€â”€ Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "SOURCE_NPZ        = RAW_TRAINING_DATA_PATH     # your 1k images\n",
    "OUTPUT_CANDIDATES = ALL_PATCHES_DATA_PATH \n",
    "\n",
    "PATCH_SIZE         = 48\n",
    "CENTER_SLICE       = slice(23, 25)\n",
    "UPSAMPLE_FACTOR    = 10\n",
    "THRESHOLD          = 0.5\n",
    "NUM_CLASSES        = 11\n",
    "SAMPLE_FRAC        = 0.10          # 10% of possible positions\n",
    "BATCH_SIZE         = 1024          # for torch interpolation\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load source\n",
    "print(\"Loading source dataset...\")\n",
    "data = np.load(SOURCE_NPZ, allow_pickle=True)\n",
    "N_images = len(data['masks'])\n",
    "print(f\"â†’ {N_images} images\")\n",
    "\n",
    "# Prepare lists\n",
    "all_patches      = []\n",
    "all_resist_avg   = []\n",
    "all_area_frac    = []\n",
    "all_source_idx   = []\n",
    "all_bbox         = []\n",
    "\n",
    "print(\"Extracting ~10% random patches per image...\")\n",
    "for img_idx in tqdm(range(N_images), desc=\"Images\"):\n",
    "    aerial = data['aerials'][img_idx]\n",
    "    resist = data['resists'][img_idx]\n",
    "    H, W = aerial.shape\n",
    "\n",
    "    # Number of samples this image\n",
    "    num_possible = (H - PATCH_SIZE + 1) * (W - PATCH_SIZE + 1)\n",
    "    num_sample = int(num_possible * SAMPLE_FRAC)\n",
    "    if num_sample < 1:\n",
    "        num_sample = 1\n",
    "\n",
    "    # Random top-left corners\n",
    "    rs = np.random.randint(0, H - PATCH_SIZE + 1, size=num_sample)\n",
    "    cs = np.random.randint(0, W - PATCH_SIZE + 1, size=num_sample)\n",
    "\n",
    "    # Collect center resist regions for batch interp\n",
    "    center_resist_list = []\n",
    "\n",
    "    for r, c in zip(rs, cs):\n",
    "        patch = aerial[r:r+PATCH_SIZE, c:c+PATCH_SIZE]\n",
    "        all_patches.append(patch)\n",
    "\n",
    "        center_res = resist[r+23:r+25, c+23:c+25]\n",
    "        center_resist_list.append(center_res)\n",
    "\n",
    "        all_resist_avg.append(center_res.mean())\n",
    "        all_source_idx.append(img_idx)\n",
    "        all_bbox.append([r, c, r+PATCH_SIZE, c+PATCH_SIZE])\n",
    "\n",
    "    # Batch interpolate resist centers\n",
    "    if center_resist_list:\n",
    "        batch_np = np.stack(center_resist_list)  # (B,2,2)\n",
    "        batch_t = torch.from_numpy(batch_np).float().to(device).unsqueeze(1)  # (B,1,2,2)\n",
    "\n",
    "        up_batch = F.interpolate(\n",
    "            batch_t,\n",
    "            scale_factor=UPSAMPLE_FACTOR,\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )  # (B,1,20,20)\n",
    "\n",
    "        fine_batch = up_batch.squeeze(1).cpu().numpy()  # (B,20,20)\n",
    "\n",
    "        for fine in fine_batch:\n",
    "            frac = (fine > THRESHOLD).sum() / fine.size\n",
    "            all_area_frac.append(frac)\n",
    "\n",
    "# Convert to arrays\n",
    "print(f\"\\nConverting images to arrays\")\n",
    "all_patches      = np.stack(all_patches)[:, None, :, :]\n",
    "all_resist_avg   = np.array(all_resist_avg, dtype=np.float32)\n",
    "all_area_frac    = np.array(all_area_frac, dtype=np.float32)\n",
    "all_source_idx   = np.array(all_source_idx, dtype=np.int64)\n",
    "all_bbox         = np.array(all_bbox, dtype=np.int64)\n",
    "\n",
    "# Add classes\n",
    "print(f\"\\nAssigning classes\")\n",
    "resist_avg_cls   = np.minimum(NUM_CLASSES-1, np.floor(all_resist_avg * 10 + 1e-9).astype(np.int64))\n",
    "area_frac_cls    = np.minimum(NUM_CLASSES-1, np.floor(all_area_frac * 10 + 1e-9).astype(np.int64))\n",
    "\n",
    "# Save\n",
    "print(f\"\\nSaving to output file: {OUTPUT_CANDIDATES}\")\n",
    "np.savez_compressed(\n",
    "    OUTPUT_CANDIDATES,\n",
    "    patches=all_patches,\n",
    "    resist_avg=all_resist_avg,\n",
    "    area_fraction=all_area_frac,\n",
    "    resist_class=resist_avg_cls,\n",
    "    area_class=area_frac_cls,\n",
    "    source_idx=all_source_idx,\n",
    "    bbox=all_bbox\n",
    ")\n",
    "\n",
    "print(f\"\\nSaved fast candidates: {OUTPUT_CANDIDATES}\")\n",
    "print(f\"Total extracted patches: {len(all_patches):,}\")\n",
    "print(f\"Resist avg mean/min/max: {all_resist_avg.mean():.4f} / {all_resist_avg.min():.4f} / {all_resist_avg.max():.4f}\")\n",
    "print(f\"Area fraction mean/min/max: {all_area_frac.mean():.4f} / {all_area_frac.min():.4f} / {all_area_frac.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53bb70ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 100,000 patches\n",
      "  â†’ 50,000 random\n",
      "  â†’ 50,000 stratified (~4,545 per class)\n",
      "Loading candidates from Stage 1...\n",
      "â†’ 873,600 total candidates\n",
      "Building per-class index lists...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713bd2e4aa304e64b9e1ac1e6a05250c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifying:   0%|          | 0/873600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw class counts (resist avg): [722845, 33333, 17321, 13278, 13838, 12793, 15322, 19469, 13756, 11645, 0]\n",
      "\n",
      "Sampling random half...\n",
      "Sampling balanced stratified half...\n",
      "  Class 0: took 4,545 / 4,545 (available: 722,845)\n",
      "  Class 1: took 4,545 / 4,545 (available: 33,333)\n",
      "  Class 2: took 4,545 / 4,545 (available: 17,321)\n",
      "  Class 3: took 4,545 / 4,545 (available: 13,278)\n",
      "  Class 4: took 4,545 / 4,545 (available: 13,838)\n",
      "  Class 5: took 4,545 / 4,545 (available: 12,793)\n",
      "  Class 6: took 4,545 / 4,545 (available: 15,322)\n",
      "  Class 7: took 4,545 / 4,545 (available: 19,469)\n",
      "  Class 8: took 4,545 / 4,545 (available: 13,756)\n",
      "  Class 9: took 4,545 / 4,545 (available: 11,645)\n",
      "Warning: class 10 has zero candidates!\n",
      "Added 4,550 extra random to reach target stratified count\n",
      "\n",
      "Combining random + stratified...\n",
      "\n",
      "Final dataset saved: data/litho_dataset_sampled_patches.npz\n",
      "Total patches: 100,000\n",
      "Class distribution (resist avg):\n",
      "[49848  6536  5643  5371  5356  5329  5496  5726  5381  5314     0]\n",
      "\n",
      "Random half class counts:\n",
      "[41551  1833  1000   747   739   710   870  1086   759   705     0]\n",
      "Stratified half class counts:\n",
      "[8297 4703 4643 4624 4617 4619 4626 4640 4622 4609    0]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  STAGE 2 â€“ Fast stratified sampling using per-class lists + final save\n",
    "# =============================================================================\n",
    "\n",
    "FINAL_NPZ = SAMPLED_PATCHES_DATA_PATH\n",
    "N_TOTAL   = 100_000\n",
    "N_RANDOM  = N_TOTAL // 2\n",
    "N_STRAT   = N_TOTAL - N_RANDOM\n",
    "QUOTA_PER_CLASS = N_STRAT // NUM_CLASSES\n",
    "\n",
    "print(f\"Target: {N_TOTAL:,} patches\")\n",
    "print(f\"  â†’ {N_RANDOM:,} random\")\n",
    "print(f\"  â†’ {N_STRAT:,} stratified (~{QUOTA_PER_CLASS:,} per class)\")\n",
    "\n",
    "# Load candidates from Stage 1\n",
    "print(\"Loading candidates from Stage 1...\")\n",
    "candidates = np.load(OUTPUT_CANDIDATES, allow_pickle=True)\n",
    "\n",
    "patches_all     = candidates['patches']\n",
    "resist_avg_all  = candidates['resist_avg']\n",
    "area_frac_all   = candidates['area_fraction']\n",
    "source_all      = candidates['source_idx']\n",
    "bbox_all        = candidates['bbox']\n",
    "\n",
    "N_all = len(patches_all)\n",
    "print(f\"â†’ {N_all:,} total candidates\")\n",
    "\n",
    "# Compute classes (using resist_avg for balancing â€” you can switch to area_frac if preferred)\n",
    "resist_avg_cls = np.minimum(NUM_CLASSES-1, np.floor(resist_avg_all * 10 + 1e-9).astype(np.int64))\n",
    "\n",
    "# Build per-class index lists\n",
    "print(\"Building per-class index lists...\")\n",
    "indices_per_class = [[] for _ in range(NUM_CLASSES)]\n",
    "\n",
    "for i in tqdm(range(N_all), desc=\"Classifying\"):\n",
    "    cls = resist_avg_cls[i]\n",
    "    indices_per_class[cls].append(i)\n",
    "\n",
    "raw_counts = [len(lst) for lst in indices_per_class]\n",
    "print(\"Raw class counts (resist avg):\", raw_counts)\n",
    "\n",
    "# â”€â”€â”€ Random half â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nSampling random half...\")\n",
    "random_indices = np.random.choice(N_all, size=N_RANDOM, replace=False)\n",
    "\n",
    "# â”€â”€â”€ Stratified half â€“ direct sampling per class â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"Sampling balanced stratified half...\")\n",
    "strat_indices = []\n",
    "\n",
    "for cls in range(NUM_CLASSES):\n",
    "    avail = indices_per_class[cls]\n",
    "    if len(avail) == 0:\n",
    "        print(f\"Warning: class {cls} has zero candidates!\")\n",
    "        continue\n",
    "    \n",
    "    n_take = min(QUOTA_PER_CLASS, len(avail))\n",
    "    chosen = np.random.choice(avail, size=n_take, replace=False)\n",
    "    strat_indices.extend(chosen)\n",
    "\n",
    "    print(f\"  Class {cls}: took {n_take:,} / {QUOTA_PER_CLASS:,} (available: {len(avail):,})\")\n",
    "\n",
    "strat_indices = np.array(strat_indices)\n",
    "\n",
    "# If we got fewer than N_STRAT due to rare classes, fill with random\n",
    "if len(strat_indices) < N_STRAT:\n",
    "    remaining = N_STRAT - len(strat_indices)\n",
    "    extra_random = np.random.choice(N_all, size=remaining, replace=False)\n",
    "    strat_indices = np.concatenate([strat_indices, extra_random])\n",
    "    print(f\"Added {remaining:,} extra random to reach target stratified count\")\n",
    "\n",
    "# â”€â”€â”€ Combine & save final dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nCombining random + stratified...\")\n",
    "\n",
    "final_indices = np.concatenate([random_indices, strat_indices])\n",
    "\n",
    "final_patches     = patches_all[final_indices]\n",
    "final_resist_avg  = resist_avg_all[final_indices]\n",
    "final_area_frac   = area_frac_all[final_indices]\n",
    "final_resist_cls  = resist_avg_cls[final_indices]\n",
    "final_area_cls    = np.minimum(NUM_CLASSES-1, np.floor(final_area_frac * 10 + 1e-9).astype(np.int64))\n",
    "final_source      = source_all[final_indices]\n",
    "final_bbox        = bbox_all[final_indices]\n",
    "final_is_random   = np.concatenate([np.ones(N_RANDOM, dtype=bool), np.zeros(len(strat_indices), dtype=bool)])\n",
    "\n",
    "np.savez_compressed(\n",
    "    FINAL_NPZ,\n",
    "    patches            = final_patches.astype(np.float32),\n",
    "    resist_avg         = final_resist_avg.astype(np.float32),\n",
    "    area_fraction      = final_area_frac.astype(np.float32),\n",
    "    resist_class       = final_resist_cls.astype(np.int64),\n",
    "    area_class         = final_area_cls.astype(np.int64),\n",
    "    source_idx         = final_source.astype(np.int64),\n",
    "    patch_bbox         = final_bbox.astype(np.int64),\n",
    "    is_random          = final_is_random,\n",
    "    class_hist_random  = np.bincount(final_resist_cls[:N_RANDOM], minlength=NUM_CLASSES),\n",
    "    class_hist_strat   = np.bincount(final_resist_cls[N_RANDOM:], minlength=NUM_CLASSES),\n",
    "    class_hist_total   = np.bincount(final_resist_cls, minlength=NUM_CLASSES)\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal dataset saved: {FINAL_NPZ}\")\n",
    "print(f\"Total patches: {len(final_patches):,}\")\n",
    "print(\"Class distribution (resist avg):\")\n",
    "print(np.bincount(final_resist_cls, minlength=NUM_CLASSES))\n",
    "print(\"\\nRandom half class counts:\")\n",
    "print(np.bincount(final_resist_cls[:N_RANDOM], minlength=NUM_CLASSES))\n",
    "print(\"Stratified half class counts:\")\n",
    "print(np.bincount(final_resist_cls[N_RANDOM:], minlength=NUM_CLASSES))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
